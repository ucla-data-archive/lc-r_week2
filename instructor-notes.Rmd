---
title: "week2-intro-r: instructor notes"
output: html_document
author: "Tim Dennis"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
books <- read_csv('data/books.csv')
books2 <- read_csv('data/books_reformatted.csv')
```

## To get the RMarkdown documents for today: 

To download to your local RStudio, open or be inside your R project from last week. In windows & mac, you can double click on the file with `.Rproj` extension. 

If you don't have a project from last week, follow these instructions to create a new project. 

1. Under the File menu, click on New project, choose New directory, then New project
2. Enter the name library_carpentry for this new folder (or “directory”). This will be your working directory for the rest of the day.
3. Click on Create project

Now, run the `download.file` function we used last week, with the URL's to the files we will use in the workshop. 

```{r rmd-notebook, eval=FALSE}
download.file('https://raw.githubusercontent.com/ucla-data-archive/lc-r_week2/main/week2-intro-r.Rmd', '.')
download.file('https://raw.githubusercontent.com/ucla-data-archive/lc-r_week2/main/exercises.Rmd', '.')
```


## Let us know if you see those in your Files pane in RStudio? 

* Use the Zoom `yes` feature

![yes or no](zoom-yes.png)

Open this file `week2-intro-r.Rmd` file by clicking on them in the Files pane. 

You will use this document to follow along with me and "live code". We will create code chunks for our R code. This will be fun! 

We will use the Rmd document `exercies.Rmd` when we go into breakout room to solve challenges. 

But first ... 

## What is RMarkdown? 

* A document type in R that lets you intersperse text, R code, images and the output of our code (this includes visualizations).
* We use the `knit` button aboveto compile this document and it will then be rendred into either a webpage, a pdf, a word document.

This will turn into an in-line image: 

![what it looks like](https://raw.githubusercontent.com/ucla-data-archive/lc-r_week2/main/rmarkdown.png)

Let's try this. Scroll up and change my name to yours, save and press `knit`.

## Last week brief review using RMarkdown

* At the end of the class we used a cleaned up version of the raw `books.csv` that was derived from the University of Houston–Clear Lake Integrated Library System in 2018.
* It is a sample of books from the catalog. 
* It consists of 10,000 observations of 11 variables. 
* We read in this data from a url like so: 

```{r books2}
books2 <- read_csv("https://raw.githubusercontent.com/LibraryCarpentry/lc-r/main/data/books_reformatted.csv")
```

We looked at the data using `glimpse`. 

```{r glimps-books}
glimpse(books2)
```

We created a subset of the data retaining only books that are in the "general collection", "juvenile" and "k12 materials" sub-collections. 

```{r subset-books-subcol}
books_plot <- books2 %>% 
  filter(subCollection == "general collection" |
         subCollection == "juvenile" |
         subCollection == "k12 materials",
         !is.na(call_class))
```

We then plotted the data using ggplot: 

```{r bar-call-class}
ggplot(data = books_plot, mapping = aes(x = call_class)) + geom_bar()
```

## This week's schedule 

How to make a table in markdown 

| Topic | Time |
| ------- | ----- | 
| Introduction to RMarkdown documents & review | 9:10 am -9:30 am |
| Cleaning and preparing data in R | 9:30 am - 10:15 am | 
| Challenges | 10:15 - 10:30 am |
| Break | 10:30 - 10:40 am |
| Visualizing data in R | 10:40 am - 11:50 |
| Break | 11:50-noon | 
| Challenges | 12:00 - 12:20  | 
| Feedback & Questions | 12:20-12:30 |
| End | 12:30 | 

## Data Cleaning & Transformation 

## Make sure our working environment set up

```{r set-up-folders, eval=FALSE}
dir.create("data")
dir.create("data_output")
dir.create("fig_output")
```

And download our books data: 

```{r dowload-data}
download.file("https://ndownloader.figshare.com/files/22031487",
              "data/books.csv", mode = "wb")
```

```{r}
books <- read_csv("./data/books.csv")

```

## Dataframes 

Inspecting data frames 

```{r inspecting-df}
dim(books)
nrow(books)
ncol(books)
head(books)
tail(books)
names(books)
#View(books)
str(books)
summary(books)
```

# dollar sign

* use to access named columns inside datat frame
* unique, table, duplicated 

```{r}
unique(books$BCODE2)
```

## Transforming data 

* dplyr gives us function to manipulate transform data frame

`rename()`: rename columns
`recode()`: recode values in a column
`select()`: subset columns
`filter()`: subset rows on conditions
`mutate()`: create new columns by using information from other columns
`group_by()` and summarize(): create summary statistics on grouped data
`arrange()`: sort results
`count()`: count discrete values

```{r}
glimpse(books)
```

```{r}
books <- rename(books, 
                title = X245.ab)
```

```{r}
names(books)
```

Let's rename all the variables so they make more sense:


```{r}
books <- rename(books, 
                author = X245.c,
                callnumber = CALL...BIBLIO.,
                isbn = ISN,
                pubyear = X008.Date.One,
                subCollection = BCODE1,
                format = BCODE2,
                location = LOCATION,
                tot_chkout = TOT.CHKOUT,
                loutdate = LOUTDATE,
                subject = SUBJECT)
```

* The `names()` function will print out our column names: 

```{r}
names(books)
```

### Recoding Values 

* We'll use `recode()` to change values 
* Let's look at the distinct values for `subCollection`
* The `distinct` function from dplyr will help wiht this

```{r}
distinct(books, subCollection)
```

* We can now recode our sub-collections from code to meaningful categories: 

```{r}
books$subCollection <- recode(books$subCollection,
                              "-" = "general collection",
                              u = "government documents",
                              r = "reference",
                              b = "k-12 materials",
                              j = "juvenile",
                              s = "special collections",
                              c = "computer files",
                              t = "theses",
                              a = "archives",
                              z = "reserves")
```

* Let's look at the top of our data frame: 

```{r}
head(books$subCollection)
```

Let's do the same for `format`:

```{r}
books$format <- recode(books$format,
                       a = "book",
                       e = "serial",
                       w = "micoform",
                       s = "e-gov doc",
                       o = "map",
                       n = "database",
                       k = "cd-rom",
                       m = "image",
                       "5" = "kit/object",
                       "4" = "online video")
```

## Subsetting with `dplyr`'s `filter()` funtion 

* The `filter()` function lets us retain rows that meet a condition
* We can make a new data frame that only contains `books` 

```{r}
booksOnly <- filter(books, format == "book")
```

* The `==` tests for sameness on each row in the format column
* We can see how this works by running that part of the code on our format column

```{r}
books$format == "book"
```

* outputs`TRUE` and `FALSE` based on whether or not its a book

```{r}
booksOnly
```

* We can use multiple filter conditions together.
* Make sure you add the comma betwee each condition 

```{r}
bookCheckouts <- filter(books,
                        format == "book",
                        tot_chkout > 0)
```

* we can use the `summary()` function to get some basic stats

```{r}
summary(bookCheckouts$tot_chkout)
```

* Any questions? 

## Selecting columns

* We can use the `select()` function to keep or remove columns from our data frame:

```{r}
booksTitleCheckouts <- select(books, title, tot_chkout)
booksTitleCheckouts
```

* The `-` subtracts the column. 

```{r}
# specify the variables you want to remove with a -
books <- select(books, -location)

# reorder columns, combined with everything()
booksReordered <- select(books, title, tot_chkout, loutdate, everything())
```

## Ordering data with `arrange()`

* `arrange()` will order columns
* we can arrange our title column

```{r}
booksTitleArrange <- arrange(books, title)
booksTitleArrange
```

* We can also arrange a numeric column
* Let's order the `tot_checkout` in `desc()` order to see the most checked out books
* We'll also save this as a data frame for future use

```{r}
booksHighestChkout <- arrange(books, desc(tot_chkout))
booksHighestChkout
```

## Creating new variables with `mutate`

* `mutate` lets us create and add variables to our data frame
* We need to create a new variable that is only the first character of our call number
* Let's look at the data frame again 
* We'll use a function `str_sub` to pick off that first character 
* When I'm working with new functions, I like to see what they do by themselves before I use in another function
* Let's see what `str_sub` does by itself 

```{r}
str_sub('ZZ4 .C64 1999', 1, 1)
```

* Ah, I see 
* Now we can use in our `mutate` funtion 

```{r}
booksLC <- mutate(books,
                  call_class = str_sub(callnumber, 1, 1))

```

* `mutate()` is also helpful to coerce a column from one data type to another. 
* For instance, there are some errors in the pubyear variable–some dates are `19zz` or `uuuu`.
* Look at data 
* Because of this, this variable was read in as a character rather than an integer
* Let's make it become an integer 

```{r}
as.integer(c('1', 'uuu'))
```


```{r}
books <- mutate(books, pubyear = as.integer(pubyear))
```

* Ok, we can use the handy `table()` function to make a frequency table of our work: 

```{r}
table(books$pubyear)
```

## Piping it together 

* The pipe operator `%>%` lets us tie together our work above (selecting, mutating, arranging, and filtering)
* Very helpful because it means we don't have to have create a bunch of intermediate data objects in our R code
* Short cut: `Ctrl` + `shift` + `M` on a PC or `Cmd` + `Shift` + `M` on a Mac.

```{r pipe}
myBooks <- books %>%
  filter(format == "book") %>%
  select(title, tot_chkout) %>%
  arrange(desc(tot_chkout))
myBooks
```

* You would read this sequence as:

1. Take books then
2. Use this output as the input to the next function `filter()` then
3. Use this output as the input to the next function `select()` then
4. Use this output as the input to the next function `arrange()`
5. Assign the resulting data frame to `myBooks`

## Split-apply-combine pattern with `summarize`

* Split data up into groups by some category in your data
* Apply some analysis to each group 
* Combine the results 

![split-apply-combine](https://miro.medium.com/max/1400/1*w2oGdXv5btEMxAkAsz8fbg.png)

* So to compute the average checkouts by format:

```{r}
books %>%
  group_by(format) %>%
  summarize(mean_checkouts = mean(tot_chkout))
```

* Here is a more complex example:

```{r}
books %>% 
  filter(format == "book") %>%
  mutate(call_class = str_sub(callnumber, 1, 1)) %>%
  group_by(call_class) %>%
  summarize(count = n(),
            sum_tot_chkout = sum(tot_chkout)) %>%
  arrange(desc(sum_tot_chkout))
```

Let's break this down step by step:
* First we call the `books` data frame
* We then pipe through `filter()` to include only books
* We then create a new column with `mutate()` called `call_class` by using the
`str_sub()` function to keep the first character of the `call_number` variable
* We then `group_by()` our newly created `call_class` variable
* We then create two summary columns by using `summarize()` 
  - take the number `n()` of items per `call_class` and assign it to a column called `count`
  - take the the `sum()` of `tot_chkout` per `call_class` and assign the result to a column called `sum_tot_chkout`
* Finally, we arrange `sum_tot_chkout` in descending order, so we can see the
class with the most total checkouts. We can see it is the `E` class (History of America), followed by `NA` (items with no call number data), followed by `H` (Social Sciences) and `P` (Language and Literature).

## pattern matching (optional if time constrained)

```{r}
glimpse(books)
```

* notice all the character variables we have
* when data cleaning we often need to manipulate these string values to extract content 
* notice in our title we have trailing slashes that came with whatever system formatting we extracted this data from  

```{r}
(head(books$title)) 
(tail(books$title))
```
* notice our subtitles also have a "|" after the ":" in the subtitle 
* we can remove these: 

```{r}
books %>% 
  mutate(title_modified = str_remove(title, "/$")) %>% 
  mutate(title_modified = str_replace(title_modified, ":+\\|", ": ")) %>% 
  select(title_modified, title)
```
* We didn't get all of the subtitles but we can continue to work out the regular expression. 

## dataviz 

Let's recreate the `booksPlot` from the end of last week. This dataframe contains only general coll, juvenile & k-12 books & filters out `NA` form call_class. 

```{r}
# create a new data frame
booksPlot <- books2 %>%
  filter(subCollection == "general collection" | 
           subCollection == "juvenile" | 
           subCollection == "k-12 materials",
         !is.na(call_class))
```

* Now we can use ggplot to plot this 
* `gg` stands for grammar of graphics and you can think about in terms of these parts: 

```{r, eval=FALSE}
ggplot(data = <DATA>, mapping = aes(<MAPPINGS>)) +  <GEOM_FUNCTION>()
```

* To plot, we need data, aesthic mapping (typically x, y axis) and a geom or geometric objects (line, bar, scatter, etc) 
* ggplot lets us layer elements on a plot

```{r}
ggplot(data = booksPlot) 
```

* gives us a blank canvas 
* next step is to define mapping 

```{r}
ggplot(data = booksPlot, mapping = aes(x = call_class)) # define the x axis aesthetic
```

* `aes` maps variables in our data frame to the plot
* but we aren't there yet, we need to tell ggplot HOW to plot
* all kinds of options here
* but since we're mapping only a single variable to the x axis that limits choices 
* we can make a bar chart:

```{r}
# add a bar geom and set call_class as the x axis
ggplot(data = booksPlot, mapping = aes(x = call_class)) +
  geom_bar()
```

* Ah ok, now we have something. H class & P class have most volumes of books. 
* Let's look at another single variable or univariate plots that works with numeric variables
* A histogram is a univariate plot: it shows the frequency counts of each value inside a single variable
* Let's look at the frequency distribution of checkouts in `booksPlot` 

```{r}
ggplot(data = booksPlot, mapping = aes(x = tot_chkout)) +
  geom_histogram()
```
* The graph is heavily skewed right to checkout - a few titles circulate a lot
* Lots of the books don't
* We can change the buckets or binwidths that `geom_hist` uses to count up occurances, this will change the shape of the plot and give us more details about the lower counts 
* We can also change the scales to help even more, so we can compare larger and smaller counts

```{r}
ggplot(data = booksPlot) +
  geom_histogram(aes(x = tot_chkout), binwidth = 10) +
  scale_y_log10()
```
* Notice the scale y axis now goes from 0-10, 10-100, 100-1000, and 1000-10000. 
* This is called “logarithmic scale” and is based on orders of magnitude.
* We can therefore see that over 5,000 books (on the y axis) have between 0-10 checkouts (on the x axis), 1,000 books have 10-20 checkouts, and further down on the x axis, a handful of books have 60-70 checkouts, and a handful more have around 100 checkouts.

* We can check this with table():

```{r}
table(booksPlot$tot_chkout)
```

* ggplot gives is a helpful way to see the distribution of checkouts 

### Change th geom 

* we can viz the same data different ways by changing the `geom_`
* let's use the `geom_density` on `tot_chkout`:

```{r}
# create a density plot
ggplot(data = booksPlot) +
  geom_density(aes(x = tot_chkout)) +
  scale_y_log10() +
  scale_x_log10()
```

# Bivariate geoms 

* Two variables 
* Usage items without `NA`s 
* Let's greater than 10 checkouts data frame 

```{r}
booksHighUsage <- booksPlot %>% 
  filter(!is.na(tot_chkout),
         tot_chkout > 10)
```

* Now we can viz with a scatter plot
* There is still so much skew that we retain the logarithmic scale on the y axis with scale_y_log10().

```{r}
# scatter plot high usage books by call number class
ggplot(data = booksHighUsage,
       aes(x = call_class, y = tot_chkout)) +
  geom_point() +
  scale_y_log10()
```

* Note `e` is an easy checkout category not e as in loc subj class (history)
* notice the scale on the y axis. 
* We can observe a few items of interest here: 
* Note items in the D, J, M, and Z class have more than 30 checkouts. 
* An item in the E class has the most checkouts with over 100, but, as noted above, this includes **Easy books** classified with E, not just items with Library of Congress E classification (United States history) an issue we’ll look at further down.
* Just as with univariate plots, we can use different geoms to view various aspects of the data, which in turn reveal different patterns.

```{r}
# boxplot plot high usage books by call number class
ggplot(data = booksHighUsage,
       aes(x = call_class, y = tot_chkout)) +
  geom_boxplot() +
  scale_y_log10()
```

* We can add points over a boxplot 
* We can add a transparency operator `alpha` - see through 
* Use `geom_jitter()` which will intro some noise 
* Add a color 

```{r}
ggplot(data = booksHighUsage, aes(x = call_class, y = tot_chkout)) +
  geom_boxplot(alpha = 0) +
  geom_jitter(alpha = 0.5, color = "tomato") +
  scale_y_log10()
```

* note the layering effect - dots over boxplot
* how would we reverse that? 
* try it

```{r}
ggplot(data = booksHighUsage, aes(x = call_class, y = tot_chkout)) +
  geom_jitter(alpha = 0.5, color = "tomato") +
  geom_boxplot(alpha = 0) +
  scale_y_log10()
```

## Three variables! 

* we can add a third variable to add color 
* we do this inside the `aes()`

```{r}
ggplot(data = booksHighUsage,
       aes(x = call_class,
           y = tot_chkout,
           color = subCollection)) +
  geom_point() +
  scale_y_log10()
```

* ggplot auto assigns hte color to each unique vaulue in the variable 
* called scaling 
* juvenile materials make up a large number of `e` and `p` classes
* let's make a bar chart with a third variable for color 

```{r}
ggplot(data = booksHighUsage, aes(x = call_class)) +
  geom_bar(aes(fill = subCollection))
```

* stacked bars are hard to read 
* let's put them side by side 

```{r}
ggplot(data = booksHighUsage, aes(x = call_class)) +
  geom_bar(aes(fill = subCollection), position = "dodge")
```

* the order of the x axis is alpha by default lets change to 

```{r}
ggplot(data = booksHighUsage, aes(x = fct_infreq(call_class))) +
  geom_bar()

```

* we can flip this on it's side too

```{r}
ggplot(data = booksHighUsage, aes(x = fct_rev(fct_infreq(call_class)))) +
  geom_bar() +
  coord_flip()
```

## Time series 

* to create a time series we need to convert our publication date to a date object in R 
* we need to install a package called `lubridate` 
* do you remember how? 

```{r}
install.packages('lubridate')
```

```{r}
library(lubridate)
```

```{r}
booksPlot <- booksPlot %>%
  mutate(pubyear_ymd = ymd(pubyear, truncated = 2))  # convert pubyear to a Date object with ymd()

```

```{r}
class(booksPlot$pubyear)  # integer
```

```{r}
class(booksPlot$pubyear_ymd)  # Date
```

* now we can filter & get counts per year

```{r}
yearly_counts <- booksPlot %>%
  filter(!is.na(pubyear_ymd),
         pubyear_ymd > "1989-01-01" & pubyear_ymd < "2002-01-01") %>%
  count(pubyear_ymd, subCollection)
```

```{r}
ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n)) +
     geom_line()
```

* this plots all our sub-collections together
* to get different lines per sub-collection we need to use the group parameter

```{r}
ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n, color = subCollection)) +
  geom_line()

```

## Faceting 

* small multiple plots by category in our data 

```{r}
ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n)) +
    geom_line() +
    facet_wrap(facets = vars(subCollection))

```

* add a theme 

```{r}
#
ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n)) +
  geom_line() +
  facet_wrap(facets = vars(subCollection)) +
  theme_bw()
```

## customization 

* we can change the labels, add a title, etc. 

```{r}
# add labels
ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n)) +
  geom_line() +
  facet_wrap(facets = vars(subCollection)) +
  theme_bw() +
    labs(title = "Number of High Usage Books per Year of Publication, by Sub-Collection",
        x = "Year of publication",
        y = "Number of books")
```

* skip ->

```{r}
# create the gray theme
gray_theme <- theme(axis.text.x = element_text(color = "gray20", size = 12, angle = 45, hjust = 0.5, vjust = 0.5),
                    axis.text.y = element_text(color = "gray20", size = 12),
                    text = element_text(size = 16),
                    plot.title = element_text(hjust = 0.5))

# pass the gray theme to a plot
ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n)) +
  geom_line() +
  facet_wrap(facets = vars(subCollection)) +
  gray_theme +
  labs(title = "Number of High Usage Books per Year of Publication, \n by Sub-Collection",
        x = "Year of publication",
        y = "Number of books")
```

## save & export 

* we can save from rstudio 
* we can also save the whole plot as an object in code and hten save 

```{r}
yearly_counts_plot <- ggplot(data = yearly_counts, mapping = aes(x = pubyear_ymd, y = n)) +
  geom_line() +
  facet_wrap(facets = vars(subCollection)) +
  gray_theme +
  labs(title = "Number of High Usage Books per Year of Publication, \n by Sub-Collection",
        x = "Year of publication",
        y = "Number of books")

ggsave("fig_output/yearly_counts_plot.png", yearly_counts_plot, width = 15, height = 10)
```

